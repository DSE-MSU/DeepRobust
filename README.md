# Attack Methods  
| Attack Methods | Attack Type | Apply Domain | Link |
|----------------|-------------|--------------|------|
| LBFGS attack | White-Box | Image Classification | [Intriguing Properties of Neural Networks](https://arxiv.org/pdf/1312.6199.pdf?not-changed)|
| FGSM attack | White-Box | Image Classification | [Explaining and Harnessing Adversarial Examples](https://arxiv.org/pdf/1412.6572.pdf) |
| PGD attack | White-Box | Image Classification | [Towards Deep Learning Models Resistant to Adversarial Attacks](https://arxiv.org/pdf/1706.06083.pdf) |
| DeepFool attack | White-Box | Image Classification | [DeepFool: a simple and accurate method to fool deep neural network](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.pdf) |

# Defense Methods
- PGD training
- FGSM training
- YOPO
- TRADES
| Defense Methods | Defense Type | Apply Domain | Link |
|-----------------|--------------|--------------|------|
| FGSM training | Adverserial Training | Image Classification | [Towards Deep Learning Models Resistant to Adversarial Attacks
](https://arxiv.org/pdf/1706.06083.pdf) |
| PGD training | Adverserial Training | Image Classification | [Intriguing Properties of Neural Networks](https://arxiv.org/pdf/1312.6199.pdf?not-changed) |
| YOPO | Adverserial Training | Image Classification | [You Only Propagate Once: Accelerating Adversarial
Training via Maximal Principle](https://arxiv.org/pdf/1905.00877.pdf) |
| TRADES | Adverserial Training | Image Classification | [Theoretically Principled Trade-off between Robustness and Accuracy](https://arxiv.org/pdf/1901.08573.pdf) |

# Our Review for Adverserial Attacks and Defenses
[Adversarial Attacks and Defenses in Images, Graphs and Text: A Review](https://arxiv.org/pdf/1909.08072.pdf)
